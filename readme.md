# ğŸ§  Python Concurrency Benchmark â€” Personal Roadmap

## ğŸ“Œ WHY am I doing this?

I want to **understand the real, practical difference** between:
- Synchronous I/O
- Thread-based concurrency
- Asyncio-based concurrency
- Hybrid setups (asyncio + threads)

---

## ğŸ§ª Benchmarks To Build

### Phase 1 â€” Baseline (CPU-Bound)

- [x] Run CPU-bound loop (e.g. char encode sum) with:
  - sync function
  - `async def`
  - threads (TBD)
- [x] Confirm there's **no benefit from asyncio** for CPU-bound tasks
- [ ] Test threads on CPU-bound and see if any GIL constraints show

### Phase 2 â€” Pure I/O (Network or Filesystem)

- [ ] Fetch N URLs with `requests` (sync baseline)
- [ ] Fetch N URLs with `requests` in `ThreadPoolExecutor`
- [ ] Fetch N URLs with `aiohttp` + `asyncio.gather`
- [ ] Fetch N URLs with hybrid: `aiohttp` + thread offload (e.g. slow file I/O in async)
---

## ğŸ“ˆ METRICS TO COLLECT

For each test:
- â±ï¸ Total wall time
- ğŸš€ Throughput = N / total time
- ğŸ•’ Avg latency (if measurable per task)
- ğŸ” Scale test at: [10, 50, 100, 500, 1000] tasks
- (Optional) ğŸ”¥ CPU usage or idle % (use `psutil`)
- (Optional) ğŸ’¾ Memory usage for large N

## ğŸ”§ IDEAS FOR NEXT STEPS

- Plot results with `matplotlib`
- Visualize latency histograms
- Build an internal "mini load tester"
- Add compressed response simulation (gzip / brotli)
- Write a conclusion file: **"What I learned"**
